import gradio as gr
import os
import time
from datetime import datetime
import cv2
import numpy as np
import torch
from app_yolo import TrackingAnything, parse_augment

# åˆå§‹åŒ–å‚æ•°
args = parse_augment()
args.port = 7860  # ä¿®æ”¹ä¸º7860ç«¯å£
args.device = "cuda:0" if torch.cuda.is_available() else "cpu"

# åˆå§‹åŒ–æ¨¡å‹
model = TrackingAnything(args.sam_checkpoint, args.xmem_checkpoint, args.e2fgvi_checkpoint, args)

# å®šä¹‰ç»“æœä¿å­˜è·¯å¾„
RESULT_BASE_PATH = r"D:\Track-Anything-master\result\track"

def create_result_dir():
    """åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„ç»“æœç›®å½•"""
    os.makedirs(RESULT_BASE_PATH, exist_ok=True)  # ç¡®ä¿åŸºç¡€ç›®å½•å­˜åœ¨
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_dir = os.path.join(RESULT_BASE_PATH, f"track_{timestamp}")
    os.makedirs(result_dir, exist_ok=True)
    return result_dir

def process_video(video_path, category_id):
    """å¤„ç†è§†é¢‘å¹¶è·Ÿè¸ªæŒ‡å®šç±»åˆ«çš„ç›®æ ‡"""
    # åˆ›å»ºç»“æœç›®å½•
    result_dir = create_result_dir()
    print(f"ç»“æœå°†ä¿å­˜åˆ°: {result_dir}")  # è°ƒè¯•ä¿¡æ¯
    
    # è¯»å–è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    frames = []
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    cap.release()
    
    # æå–çº¯æ•°å­—çš„ç±»åˆ«ID
    category_id = int(category_id.split("-")[0])
    
    # é‡ç½®æ¨¡å‹çŠ¶æ€
    model.reset_tracker()
    model.set_current_category(category_id)
    
    # å¤„ç†ç¬¬ä¸€å¸§
    first_frame = frames[0]
    model.init_first_frame(first_frame)
    
    # è·Ÿè¸ªè§†é¢‘
    results = []
    for i, frame in enumerate(frames):
        result = model.track_frame(frame, category_id)  # ä¼ å…¥å½“å‰ç±»åˆ«ID
        results.append(result)
        
        # ä¿å­˜æ¯ä¸€å¸§ç»“æœ
        frame_path = os.path.join(result_dir, f"frame_{i:04d}.png")
        cv2.imwrite(frame_path, cv2.cvtColor(result, cv2.COLOR_RGB2BGR))
    
    # ç”Ÿæˆç»“æœè§†é¢‘
    output_video_path = os.path.join(result_dir, "tracking_result.mp4")
    generate_output_video(results, output_video_path)
    
    # ä¿å­˜æ—¥å¿—
    log_path = os.path.join(result_dir, "tracking_log.txt")
    with open(log_path, "w") as f:
        f.write(f"Tracking completed at {datetime.now()}\n")
        f.write(f"Video: {os.path.basename(video_path)}\n")
        f.write(f"Category: {category_id}\n")
        f.write(f"Total frames: {len(frames)}\n")
    
    return output_video_path, f"è·Ÿè¸ªå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {result_dir}"

def generate_output_video(frames, output_path):
    """ç”Ÿæˆè¾“å‡ºè§†é¢‘"""
    if not frames:
        return None
    
    height, width = frames[0].shape[:2]
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))
    
    for frame in frames:
        out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
    out.release()

# Gradioç•Œé¢
with gr.Blocks(title="ç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ") as demo:
    gr.Markdown("# ğŸ¯ ç›®æ ‡è·Ÿè¸ªç³»ç»Ÿ")
    gr.Markdown("ä¸Šä¼ è§†é¢‘å¹¶é€‰æ‹©ç›®æ ‡ç±»åˆ«ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è·Ÿè¸ªä¸åŒç±»åˆ«çš„ç›®æ ‡")
    
    with gr.Row():
        with gr.Column():
            video_input = gr.Video(label="ä¸Šä¼ è§†é¢‘")
            category_dropdown = gr.Dropdown(
                choices=["1-é»˜è®¤ç±»åˆ«", "2-äººç‰©", "3-è½¦è¾†", "4-åŠ¨ç‰©", "5-å…¶ä»–"],
                value="1-é»˜è®¤ç±»åˆ«",
                label="é€‰æ‹©ç›®æ ‡ç±»åˆ«"
            )
            submit_btn = gr.Button("å¼€å§‹è·Ÿè¸ª", variant="primary")
        
        with gr.Column():
            output_video = gr.Video(label="è·Ÿè¸ªç»“æœ")
            status_output = gr.Textbox(label="çŠ¶æ€ä¿¡æ¯")
    
    # æŒ‰é’®ç‚¹å‡»äº‹ä»¶
    submit_btn.click(
        fn=process_video,
        inputs=[video_input, category_dropdown],
        outputs=[output_video, status_output],
        api_name="track_object"
    )

# å¯åŠ¨ç•Œé¢
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=args.port)